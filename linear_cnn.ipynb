{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n",
      "Building Train Data loader for dataset:  Co3d(19800 pairs,split='train',seed=None,resolutions=[512x512],transform=Compose( ToTensor() Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))))\n",
      "Train dataset length:  19800\n"
     ]
    }
   ],
   "source": [
    "import torchprofile\n",
    "from torchinfo import summary\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.datasets.co3d import Co3d\n",
    "from dust3r.datasets import get_data_loader \n",
    "def build_dataset(dataset, batch_size, num_workers, test=False):\n",
    "    split = ['Train', 'Test'][test]\n",
    "    print(f'Building {split} Data loader for dataset: ', dataset)\n",
    "    loader = get_data_loader(dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             num_workers=num_workers,\n",
    "                             pin_mem=True,\n",
    "                             shuffle=not (test),\n",
    "                             drop_last=not (test))\n",
    "\n",
    "    print(f\"{split} dataset length: \", len(loader))\n",
    "    return loader\n",
    "args = {}\n",
    "inf = float('inf')\n",
    "dataset = Co3d(split='train', ROOT=\"data/co3d_subset_processed\", resolution=512, aug_crop=16)\n",
    "data_loader_train = build_dataset(dataset,1, 1, test=False)\n",
    "view1, view2 = next(iter(data_loader_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 566476808\n",
      "13 13\n",
      "GFLOPs: 1291.126442241\n",
      "FLOPs: 1291126442241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scalarimplicit\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::arange\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::cartesian_prod\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::pow\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reciprocal\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::cos\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::neg\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::linalg_vector_norm\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expm1\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchprofile\n",
    "\n",
    "args = {\n",
    "    'pos_embed': 'RoPE100',\n",
    "    'img_size': (512, 512),\n",
    "    'head_type': 'dsca',\n",
    "    'output_mode': 'pts3d',\n",
    "    'depth_mode': ('exp', -inf, inf),\n",
    "    'conf_mode': ('exp', 1, inf),\n",
    "    'enc_embed_dim': 1024,\n",
    "    'enc_depth': 24,\n",
    "    'enc_num_heads': 16,\n",
    "    'dec_embed_dim': 768,\n",
    "    'dec_depth': 12,\n",
    "    'dec_num_heads': 12\n",
    "}\n",
    "model = AsymmetricCroCo3DStereo(**args)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameters:\", total_params)\n",
    "\n",
    "#model.__repr__\n",
    "#summary(model,col_names=(\"input_size\",\"output_size\",\"num_params\",),row_settings=('var_names','depth'), depth=10,input_size=(3,224,224))\n",
    "# 모델 FLOPs 측정\n",
    "flops = torchprofile.profile_macs(model, (view1, view2))\n",
    "gflops = flops / 1e9\n",
    "\n",
    "print(f\"GFLOPs: {gflops}\")\n",
    "print(f\"FLOPs: {flops}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 571171208\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'pos_embed': 'RoPE100',\n",
    "    'img_size': (512, 512),\n",
    "    'head_type': 'dpt',\n",
    "    'output_mode': 'pts3d',\n",
    "    'depth_mode': ('exp', -inf, inf),\n",
    "    'conf_mode': ('exp', 1, inf),\n",
    "    'enc_embed_dim': 1024,\n",
    "    'enc_depth': 24,\n",
    "    'enc_num_heads': 16,\n",
    "    'dec_embed_dim': 768,\n",
    "    'dec_depth': 12,\n",
    "    'dec_num_heads': 12\n",
    "}\n",
    "model = AsymmetricCroCo3DStereo(**args)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++DPThead+++++++++++++++++++\n",
      "layers0 torch.Size([1, 1024, 1024])\n",
      "layers1 torch.Size([1, 1024, 768])\n",
      "layers2 torch.Size([1, 1024, 768])\n",
      "layers3 torch.Size([1, 1024, 768])\n",
      "++++++++++++++++++++++++++++++++\n",
      "reshape0 torch.Size([1, 1024, 32, 32])\n",
      "reshape1 torch.Size([1, 768, 32, 32])\n",
      "reshape2 torch.Size([1, 768, 32, 32])\n",
      "reshape3 torch.Size([1, 768, 32, 32])\n",
      "++++++++++++++++++++++++++++++++\n",
      "ks0 torch.Size([1, 96, 16, 16])\n",
      "ks1 torch.Size([1, 192, 16, 16])\n",
      "ks2 torch.Size([1, 384, 16, 16])\n",
      "ks3 torch.Size([1, 768, 16, 16])\n",
      "vs0 torch.Size([1, 96, 16, 16])\n",
      "vs1 torch.Size([1, 192, 16, 16])\n",
      "vs2 torch.Size([1, 384, 16, 16])\n",
      "vs3 torch.Size([1, 768, 16, 16])\n",
      "qs0 torch.Size([1, 96, 32, 32])\n",
      "qs1 torch.Size([1, 192, 32, 32])\n",
      "qs2 torch.Size([1, 384, 32, 32])\n",
      "qs3 torch.Size([1, 768, 32, 32])\n",
      "q torch.Size([1, 96, 1024])\n",
      "k torch.Size([1, 96, 256])\n",
      "v torch.Size([1, 96, 256])\n",
      "q torch.Size([1, 192, 1024])\n",
      "k torch.Size([1, 192, 256])\n",
      "v torch.Size([1, 192, 256])\n",
      "q torch.Size([1, 384, 1024])\n",
      "k torch.Size([1, 384, 256])\n",
      "v torch.Size([1, 384, 256])\n",
      "q torch.Size([1, 768, 1024])\n",
      "k torch.Size([1, 768, 256])\n",
      "v torch.Size([1, 768, 256])\n",
      "act_postprocess0 torch.Size([1, 96, 128, 128])\n",
      "act_postprocess1 torch.Size([1, 192, 64, 64])\n",
      "act_postprocess2 torch.Size([1, 384, 32, 32])\n",
      "act_postprocess3 torch.Size([1, 768, 16, 16])\n",
      "++++++++++++++++++++++++++++++++\n",
      "rn0 torch.Size([1, 256, 128, 128])\n",
      "rn1 torch.Size([1, 256, 64, 64])\n",
      "rn2 torch.Size([1, 256, 32, 32])\n",
      "rn3 torch.Size([1, 256, 16, 16])\n",
      "++++++++++++++++++++++++++++++++\n",
      "layers3 torch.Size([1, 256, 16, 16])\n",
      "path4 torch.Size([1, 256, 32, 32]) layer2 torch.Size([1, 256, 32, 32])\n",
      "path3 torch.Size([1, 256, 64, 64]) layer1: torch.Size([1, 256, 64, 64])\n",
      "path2 torch.Size([1, 256, 128, 128]) layer0: torch.Size([1, 256, 128, 128])\n",
      "path1 torch.Size([1, 256, 256, 256])\n",
      "+++++++++++++++++++DPThead+++++++++++++++++++\n",
      "layers0 torch.Size([1, 1024, 1024])\n",
      "layers1 torch.Size([1, 1024, 768])\n",
      "layers2 torch.Size([1, 1024, 768])\n",
      "layers3 torch.Size([1, 1024, 768])\n",
      "++++++++++++++++++++++++++++++++\n",
      "reshape0 torch.Size([1, 1024, 32, 32])\n",
      "reshape1 torch.Size([1, 768, 32, 32])\n",
      "reshape2 torch.Size([1, 768, 32, 32])\n",
      "reshape3 torch.Size([1, 768, 32, 32])\n",
      "++++++++++++++++++++++++++++++++\n",
      "ks0 torch.Size([1, 96, 16, 16])\n",
      "ks1 torch.Size([1, 192, 16, 16])\n",
      "ks2 torch.Size([1, 384, 16, 16])\n",
      "ks3 torch.Size([1, 768, 16, 16])\n",
      "vs0 torch.Size([1, 96, 16, 16])\n",
      "vs1 torch.Size([1, 192, 16, 16])\n",
      "vs2 torch.Size([1, 384, 16, 16])\n",
      "vs3 torch.Size([1, 768, 16, 16])\n",
      "qs0 torch.Size([1, 96, 32, 32])\n",
      "qs1 torch.Size([1, 192, 32, 32])\n",
      "qs2 torch.Size([1, 384, 32, 32])\n",
      "qs3 torch.Size([1, 768, 32, 32])\n",
      "q torch.Size([1, 96, 1024])\n",
      "k torch.Size([1, 96, 256])\n",
      "v torch.Size([1, 96, 256])\n",
      "q torch.Size([1, 192, 1024])\n",
      "k torch.Size([1, 192, 256])\n",
      "v torch.Size([1, 192, 256])\n",
      "q torch.Size([1, 384, 1024])\n",
      "k torch.Size([1, 384, 256])\n",
      "v torch.Size([1, 384, 256])\n",
      "q torch.Size([1, 768, 1024])\n",
      "k torch.Size([1, 768, 256])\n",
      "v torch.Size([1, 768, 256])\n",
      "act_postprocess0 torch.Size([1, 96, 128, 128])\n",
      "act_postprocess1 torch.Size([1, 192, 64, 64])\n",
      "act_postprocess2 torch.Size([1, 384, 32, 32])\n",
      "act_postprocess3 torch.Size([1, 768, 16, 16])\n",
      "++++++++++++++++++++++++++++++++\n",
      "rn0 torch.Size([1, 256, 128, 128])\n",
      "rn1 torch.Size([1, 256, 64, 64])\n",
      "rn2 torch.Size([1, 256, 32, 32])\n",
      "rn3 torch.Size([1, 256, 16, 16])\n",
      "++++++++++++++++++++++++++++++++\n",
      "layers3 torch.Size([1, 256, 16, 16])\n",
      "path4 torch.Size([1, 256, 32, 32]) layer2 torch.Size([1, 256, 32, 32])\n",
      "path3 torch.Size([1, 256, 64, 64]) layer1: torch.Size([1, 256, 64, 64])\n",
      "path2 torch.Size([1, 256, 128, 128]) layer0: torch.Size([1, 256, 128, 128])\n",
      "path1 torch.Size([1, 256, 256, 256])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512, 3])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512, 3])\n"
     ]
    }
   ],
   "source": [
    "pred1, pred2 = model(view1, view2)\n",
    "print(pred1['conf'].shape)\n",
    "print(pred1['pts3d'].shape)\n",
    "\n",
    "print(pred2['conf'].shape)\n",
    "print(pred2['pts3d_in_other_view'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512, 3])\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 512, 512, 3])\n"
     ]
    }
   ],
   "source": [
    "print(pred1['conf'].shape)\n",
    "print(pred1['pts3d'].shape)\n",
    "\n",
    "print(pred2['conf'].shape)\n",
    "print(pred2['pts3d_in_other_view'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++ENCODER++++++++++++++++++\n",
    "feat1 torch.Size([1, 1024, 1024])\n",
    "feat2 torch.Size([1, 1024, 1024])\n",
    "++++++++++++++++++DECODER++++++++++++++++++\n",
    "0 _f1 torch.Size([1, 1024, 1024])\n",
    "0 _f2 torch.Size([1, 1024, 1024])\n",
    "decoder_embed f1 torch.Size([1, 1024, 768])\n",
    "decoder_embed f2 torch.Size([1, 1024, 768])\n",
    "1 _f1 torch.Size([1, 1024, 768])\n",
    "1 _f2 torch.Size([1, 1024, 768])\n",
    "2 _f1 torch.Size([1, 1024, 768])\n",
    "2 _f2 torch.Size([1, 1024, 768])\n",
    "3 _f1 torch.Size([1, 1024, 768])\n",
    "3 _f2 torch.Size([1, 1024, 768])\n",
    "4 _f1 torch.Size([1, 1024, 768])\n",
    "4 _f2 torch.Size([1, 1024, 768])\n",
    "5 _f1 torch.Size([1, 1024, 768])\n",
    "5 _f2 torch.Size([1, 1024, 768])\n",
    "6 _f1 torch.Size([1, 1024, 768])\n",
    "6 _f2 torch.Size([1, 1024, 768])\n",
    "7 _f1 torch.Size([1, 1024, 768])\n",
    "7 _f2 torch.Size([1, 1024, 768])\n",
    "8 _f1 torch.Size([1, 1024, 768])\n",
    "8 _f2 torch.Size([1, 1024, 768])\n",
    "9 _f1 torch.Size([1, 1024, 768])\n",
    "9 _f2 torch.Size([1, 1024, 768])\n",
    "10 _f1 torch.Size([1, 1024, 768])\n",
    "10 _f2 torch.Size([1, 1024, 768])\n",
    "11 _f1 torch.Size([1, 1024, 768])\n",
    "11 _f2 torch.Size([1, 1024, 768])\n",
    "12 _f1 torch.Size([1, 1024, 768])\n",
    "12 _f2 torch.Size([1, 1024, 768])\n",
    "final_output before 14\n",
    "final_output after 13\n",
    "13\n",
    "+++++++++++++++++++DPThead+++++++++++++++++++\n",
    "adapt_tokens0 torch.Size([1, 1024, 1024])\n",
    "adapt_tokens1 torch.Size([1, 1024, 768])\n",
    "adapt_tokens2 torch.Size([1, 1024, 768])\n",
    "adapt_tokens3 torch.Size([1, 1024, 768])\n",
    "++++++++++++++++++++++++++++++++\n",
    "reshape0 torch.Size([1, 1024, 32, 32])\n",
    "reshape1 torch.Size([1, 768, 32, 32])\n",
    "reshape2 torch.Size([1, 768, 32, 32])\n",
    "reshape3 torch.Size([1, 768, 32, 32])\n",
    "++++++++++++++++++++++++++++++++\n",
    "act_postprocess0 torch.Size([1, 96, 128, 128])\n",
    "act_postprocess1 torch.Size([1, 192, 64, 64])\n",
    "act_postprocess2 torch.Size([1, 384, 32, 32])\n",
    "act_postprocess3 torch.Size([1, 768, 16, 16])\n",
    "++++++++++++++++++++++++++++++++\n",
    "rn0 torch.Size([1, 256, 128, 128])\n",
    "rn1 torch.Size([1, 256, 64, 64])\n",
    "rn2 torch.Size([1, 256, 32, 32])\n",
    "rn3 torch.Size([1, 256, 16, 16])\n",
    "++++++++++++++++++++++++++++++++\n",
    "layers3 torch.Size([1, 256, 16, 16])\n",
    "path4 torch.Size([1, 256, 32, 32]) layer2 torch.Size([1, 256, 32, 32])\n",
    "path3 torch.Size([1, 256, 64, 64]) layer1: torch.Size([1, 256, 64, 64])\n",
    "path2 torch.Size([1, 256, 128, 128]) layer0: torch.Size([1, 256, 128, 128])\n",
    "path1 torch.Size([1, 256, 256, 256])\n",
    "+++++++++++++++++++DPThead+++++++++++++++++++\n",
    "adapt_tokens0 torch.Size([1, 1024, 1024])\n",
    "adapt_tokens1 torch.Size([1, 1024, 768])\n",
    "adapt_tokens2 torch.Size([1, 1024, 768])\n",
    "adapt_tokens3 torch.Size([1, 1024, 768])\n",
    "++++++++++++++++++++++++++++++++\n",
    "reshape0 torch.Size([1, 1024, 32, 32])\n",
    "reshape1 torch.Size([1, 768, 32, 32])\n",
    "reshape2 torch.Size([1, 768, 32, 32])\n",
    "reshape3 torch.Size([1, 768, 32, 32])\n",
    "++++++++++++++++++++++++++++++++\n",
    "act_postprocess0 torch.Size([1, 96, 128, 128])\n",
    "act_postprocess1 torch.Size([1, 192, 64, 64])\n",
    "act_postprocess2 torch.Size([1, 384, 32, 32])\n",
    "act_postprocess3 torch.Size([1, 768, 16, 16])\n",
    "++++++++++++++++++++++++++++++++\n",
    "rn0 torch.Size([1, 256, 128, 128])\n",
    "rn1 torch.Size([1, 256, 64, 64])\n",
    "rn2 torch.Size([1, 256, 32, 32])\n",
    "rn3 torch.Size([1, 256, 16, 16])\n",
    "++++++++++++++++++++++++++++++++\n",
    "layers3 torch.Size([1, 256, 16, 16])\n",
    "path4 torch.Size([1, 256, 32, 32]) layer2 torch.Size([1, 256, 32, 32])\n",
    "path3 torch.Size([1, 256, 64, 64]) layer1: torch.Size([1, 256, 64, 64])\n",
    "path2 torch.Size([1, 256, 128, 128]) layer0: torch.Size([1, 256, 128, 128])\n",
    "path1 torch.Size([1, 256, 256, 256])\n",
    "torch.Size([1, 512, 512])\n",
    "torch.Size([1, 512, 512, 3])\n",
    "\n",
    "헤더의 첫 입력은 인코더에서 나온 출력, 두번째 부터 디코더에서 나온 출력\n",
    "원래는 reshape해주고 act_postprocess 에서 cnn과 cnntranspose를 해주고 (w,h)를 2배로 증가\n",
    "그 결과를 layer_rn층을 통과하는데 이 층의 역할은 차원을 통일시켜주는 역할이다. (c)를 통일 시켜줌\n",
    "다음에 fuse층을 통과하면 잔차연결을 통해 레이어를 통합,확장시켜준다. (c,w,h)+(c,w,h) = (c,w*2,h*2) 이 과정을 hierachical하게 반복하면서\n",
    "최종적으로 (last_dim = feature_dim//2, 256, 256)이 나오게 된다.\n",
    "\n",
    "\n",
    "\n",
    "adapt_tokens 에나온 출력을 활용해서 CA를 하는 방안을 생각해보자\n",
    "그러면 그 결과를 reshape해서 다시 act_postprocess로 넣어주고...\n",
    "크로스어텐션한 결과를 써주니까 레이어를 퓨전하는 과정을 생략해도 될 것 같다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dust3r.dpt_custom import DPTOutputAdapter\n",
    "\n",
    "args = {\n",
    "    'num_channels': 1,\n",
    "    'stride_level': 1,\n",
    "    'patch_size': 16,\n",
    "    'main_tasks': ('rgb',),\n",
    "    'hooks': [2, 5, 8, 11],\n",
    "    'layer_dims': [96, 192, 384, 768],\n",
    "    'feature_dim': 196,\n",
    "    'last_dim': 32,\n",
    "    'use_bn': False,\n",
    "    'dim_tokens_enc': 768,\n",
    "    'head_type': 'regression',\n",
    "    'output_width_ratio': 1\n",
    "}\n",
    "model = DPTOutputAdapter(**args)\n",
    "model.init()\n",
    "#print(model.__repr__())\n",
    "# Create dummy input\n",
    "encoder_tokens = [(torch.ones(1,1024,768)+i) for i in range(13)]\n",
    "\n",
    "image_size = (512, 512)\n",
    "\n",
    "# Forward pass\n",
    "output = model(encoder_tokens, image_size)\n",
    "\n",
    "# Print the output\n",
    "print(\"output\",output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'Moudle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustom_Head\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMoudle\u001b[49m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      6\u001b[0m                  last_dim,\n\u001b[1;32m      7\u001b[0m                  use_bn,\n\u001b[1;32m      8\u001b[0m                  dim_tokens_enc,\n\u001b[1;32m      9\u001b[0m                  output_width_ratio,\n\u001b[1;32m     10\u001b[0m                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'Moudle'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Custom_Head(nn.Moudle):\n",
    "    def __init__(self,\n",
    "                 last_dim,\n",
    "                 use_bn,\n",
    "                 dim_tokens_enc,\n",
    "                 output_width_ratio,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]])\n",
      "tensor([[[2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         ...,\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.]]])\n",
      "tensor([[[3., 3., 3.,  ..., 3., 3., 3.],\n",
      "         [3., 3., 3.,  ..., 3., 3., 3.],\n",
      "         [3., 3., 3.,  ..., 3., 3., 3.],\n",
      "         ...,\n",
      "         [3., 3., 3.,  ..., 3., 3., 3.],\n",
      "         [3., 3., 3.,  ..., 3., 3., 3.],\n",
      "         [3., 3., 3.,  ..., 3., 3., 3.]]])\n",
      "tensor([[[4., 4., 4.,  ..., 4., 4., 4.],\n",
      "         [4., 4., 4.,  ..., 4., 4., 4.],\n",
      "         [4., 4., 4.,  ..., 4., 4., 4.],\n",
      "         ...,\n",
      "         [4., 4., 4.,  ..., 4., 4., 4.],\n",
      "         [4., 4., 4.,  ..., 4., 4., 4.],\n",
      "         [4., 4., 4.,  ..., 4., 4., 4.]]])\n",
      "tensor([[[5., 5., 5.,  ..., 5., 5., 5.],\n",
      "         [5., 5., 5.,  ..., 5., 5., 5.],\n",
      "         [5., 5., 5.,  ..., 5., 5., 5.],\n",
      "         ...,\n",
      "         [5., 5., 5.,  ..., 5., 5., 5.],\n",
      "         [5., 5., 5.,  ..., 5., 5., 5.],\n",
      "         [5., 5., 5.,  ..., 5., 5., 5.]]])\n",
      "tensor([[[6., 6., 6.,  ..., 6., 6., 6.],\n",
      "         [6., 6., 6.,  ..., 6., 6., 6.],\n",
      "         [6., 6., 6.,  ..., 6., 6., 6.],\n",
      "         ...,\n",
      "         [6., 6., 6.,  ..., 6., 6., 6.],\n",
      "         [6., 6., 6.,  ..., 6., 6., 6.],\n",
      "         [6., 6., 6.,  ..., 6., 6., 6.]]])\n",
      "tensor([[[7., 7., 7.,  ..., 7., 7., 7.],\n",
      "         [7., 7., 7.,  ..., 7., 7., 7.],\n",
      "         [7., 7., 7.,  ..., 7., 7., 7.],\n",
      "         ...,\n",
      "         [7., 7., 7.,  ..., 7., 7., 7.],\n",
      "         [7., 7., 7.,  ..., 7., 7., 7.],\n",
      "         [7., 7., 7.,  ..., 7., 7., 7.]]])\n",
      "tensor([[[8., 8., 8.,  ..., 8., 8., 8.],\n",
      "         [8., 8., 8.,  ..., 8., 8., 8.],\n",
      "         [8., 8., 8.,  ..., 8., 8., 8.],\n",
      "         ...,\n",
      "         [8., 8., 8.,  ..., 8., 8., 8.],\n",
      "         [8., 8., 8.,  ..., 8., 8., 8.],\n",
      "         [8., 8., 8.,  ..., 8., 8., 8.]]])\n",
      "tensor([[[9., 9., 9.,  ..., 9., 9., 9.],\n",
      "         [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "         [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "         ...,\n",
      "         [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "         [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "         [9., 9., 9.,  ..., 9., 9., 9.]]])\n",
      "tensor([[[10., 10., 10.,  ..., 10., 10., 10.],\n",
      "         [10., 10., 10.,  ..., 10., 10., 10.],\n",
      "         [10., 10., 10.,  ..., 10., 10., 10.],\n",
      "         ...,\n",
      "         [10., 10., 10.,  ..., 10., 10., 10.],\n",
      "         [10., 10., 10.,  ..., 10., 10., 10.],\n",
      "         [10., 10., 10.,  ..., 10., 10., 10.]]])\n",
      "tensor([[[11., 11., 11.,  ..., 11., 11., 11.],\n",
      "         [11., 11., 11.,  ..., 11., 11., 11.],\n",
      "         [11., 11., 11.,  ..., 11., 11., 11.],\n",
      "         ...,\n",
      "         [11., 11., 11.,  ..., 11., 11., 11.],\n",
      "         [11., 11., 11.,  ..., 11., 11., 11.],\n",
      "         [11., 11., 11.,  ..., 11., 11., 11.]]])\n",
      "tensor([[[12., 12., 12.,  ..., 12., 12., 12.],\n",
      "         [12., 12., 12.,  ..., 12., 12., 12.],\n",
      "         [12., 12., 12.,  ..., 12., 12., 12.],\n",
      "         ...,\n",
      "         [12., 12., 12.,  ..., 12., 12., 12.],\n",
      "         [12., 12., 12.,  ..., 12., 12., 12.],\n",
      "         [12., 12., 12.,  ..., 12., 12., 12.]]])\n",
      "tensor([[[13., 13., 13.,  ..., 13., 13., 13.],\n",
      "         [13., 13., 13.,  ..., 13., 13., 13.],\n",
      "         [13., 13., 13.,  ..., 13., 13., 13.],\n",
      "         ...,\n",
      "         [13., 13., 13.,  ..., 13., 13., 13.],\n",
      "         [13., 13., 13.,  ..., 13., 13., 13.],\n",
      "         [13., 13., 13.,  ..., 13., 13., 13.]]])\n"
     ]
    }
   ],
   "source": [
    "encoder_tokens = [(torch.ones(1,1024,768)+i) for i in range(13)]\n",
    "for i in range(13):\n",
    "    print(encoder_tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d parameter sizes:\n",
      "weight: torch.Size([768, 768, 1])\n",
      "bias: torch.Size([768])\n",
      "\n",
      "linear parameter sizes:\n",
      "weight: torch.Size([768, 768])\n",
      "bias: torch.Size([768])\n",
      "The difference in parameter count between conv1d and linear is: 0\n"
     ]
    }
   ],
   "source": [
    "# from torch import nn\n",
    "# from torch import torch\n",
    "\n",
    "# input_size = 768\n",
    "# output_size = 768\n",
    "# input_tensor = torch.randn(1, 768, 768)\n",
    "\n",
    "# conv1d = nn.Conv1d(768, 768,1)\n",
    "# linear = nn.Linear(768, 768)\n",
    "# print(\"conv1d parameter sizes:\")\n",
    "# for name, param in conv1d.named_parameters():\n",
    "#     print(f\"{name}: {param.size()}\")\n",
    "\n",
    "# print(\"\\nlinear parameter sizes:\")\n",
    "# for name, param in linear.named_parameters():\n",
    "#     print(f\"{name}: {param.size()}\")\n",
    "\n",
    "# conv1d_params = sum(p.numel() for p in conv1d.parameters())\n",
    "# linear_params = sum(p.numel() for p in linear.parameters())\n",
    "\n",
    "# param_diff = conv1d_params - linear_params\n",
    "# print(f\"The difference in parameter count between conv1d and linear is: {param_diff}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
